\RequirePackage[l2tabu,orthodox]{nag}
\documentclass{article}
\pdfoutput=1
\pdfminorversion=4
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{subfigure} 
\usepackage{url}
\usepackage{natbib}
\usepackage[hyperfootnotes=false,hidelinks=true]{hyperref}

\title{Ncpol2sdpa Manual}
\author{Peter Wittek\\
        \small{ICFO-The Institute of Photonic Sciences and University of Bor\aa{}s}
}
\date{}
\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
Ncpol2sdpa is a tool to convert a polynomial optimization problem of noncommuting variables to a sparse semidefinite programming (SDP) problem that can be processed by the SDPA\footnote{\url{http://sdpa.sourceforge.net/}} family of solvers~\cite{yamashita2003sdpara}. The optimization problem can be unconstrained or constrained by equalities and inequalities.

The objective is to be able to solve very large scale optimization problems. For example, a convergent series of lower bounds can be obtained for ground state problems with arbitrary Hamiltonians.

The implementation has an intuitive syntax for entering Hamiltonians and it scales for a larger number of noncommuting variables using a sparse representation of the SDP problem. The code is available in the Python Package Index at \url{https://pypi.python.org/pypi/ncpol2sdpa/} and the development version is at \url{http://peterwittek.github.io/ncpol2sdpa/}.

For further information on the internal workings of the library, please refer to corresponding paper~\citep{wittek2014ncpol2sdpa}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Dependencies and compilation}
The implementation requires SymPy\footnote{\url{http://sympy.org/}}$\geq0.7.2$ ~\citep{joyner2012open} and SciPy\footnote{\url{http://scipy.org/}} in the Python search path. The code is compatible with both Python 2 and 3, but using version 3 incurs a major decrease in performance. Follow the standard procedure for installing Python modules:
\begin{verbatim}
$ sudo pip install ncpol2sdpa
\end{verbatim}
If you use the development version, install it from the source code:
\begin{verbatim}
$ sudo python setup.py install
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Usage}
The implementation follows an object-oriented design. The core object is SdpRelaxation. There are three steps to generate the relaxation:
\begin{enumerate}
  \item Instantiate the SdpRelaxation object.
  \item Get the relaxation.
  \item Write the relaxation to a file or solve the problem.
\end{enumerate}

The second step is the most time consuming, often running for hours as the number of noncommuting variables increases.

To instantiate the SdpRelaxation object, you need to specify the noncommuting variables:
\begin{verbatim}
X = ... # Define noncommuting variables
sdpRelaxation = SdpRelaxation(X)
\end{verbatim}

Getting the relaxation also follows an almost identical syntax. It requires all the information about the polynomial optimization problem itself: the objective function, an associative array of the inequalities, equalities, the monomial substitutions, and also the level of the relaxation:
\begin{verbatim}
sdpRelaxation.get_relaxation(obj, inequalities, equalities, 
                      monomial_substitution, level)
\end{verbatim}

The last step in is to write out the relaxation to a sparse SDPA file. The method (\verb+write_to_sdpa+) takes one parameter, the file name. Alternatively, if SDPA is in the search path, then it can be solved by invoking a helper function (\verb+solve_sdp+). Using a compatibility layer to PICOS\footnote{\url{http://picos.zib.de/}}, it is also possible to solve the problem with a range of other solvers, including CVXOPT\footnote{\url{http://cvxopt.org/}} and MOSEK\footnote{\url{http://www.mosek.com/}}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Examples}
\subsection{Example 1: Toy example}\label{example1}
Consider the following polynomial optimization problem~\citep{pironio2010convergent}:

\[ \min_{x\in \mathbb{R}^2}x_1x_2+x_2x_1\]

such that

\[ -x_2^2+x_2+0.5\geq 0\]

\[x_1^2-x_1=0.\]

Entering the objective function and the inequality constraint is easy. The equality constraint is a simple projection. We either substitute two inequalities to replace the equality, or treat the equality as a monomial substitution. The second option leads to a sparser SDP relaxation. The code samples below take this approach. In this case, the monomial basis is $\{1, x_1, x_2, x_1x_2, x_2x_1, x_2^2\}$. The corresponding relaxation is written as

\[ \min_{y}y_{12}+y_{21}\]

such that
\[
\left[\begin{array}{c|cc|ccc}
1 & y_{1} & y_{2} & y_{12} & y_{21} & y_{22}\\
\hline{}
y_{1} & y_{1} & y_{12} & y_{12} & y_{121} & y_{122}\\
y_{2} & y_{21} & y_{22} & y_{212} & y_{221} & y_{222}\\
\hline{}
y_{21} & y_{21} & y_{212} & y_{212} & y_{2121} & y_{2122} \\
y_{12} & y_{121} & y_{122} & y_{1212} & y_{1221} & y_{1222}\\
y_{22} & y_{221} & y_{222} & y_{2212} & y_{2221} & y_{2222}
\end{array} \right] \succeq{}0
\]

\[
\left[ \begin{array}{c|cc}
-y_{22}+y_{2}+0.5 & -y_{221}+y_{21}+0.5y_{1} & -y_{222}+y_{22}+0.5y_{2}\\
\hline{}
-y_{221}+y_{21}+0.5y_{1} & -y_{1221}+y_{121}+0.5y_{1} & -y_{1222}+y_{122}+0.5y_{12}\\
-y_{222}+y_{22}+0.5y_{2} & -y_{1222}+y_{122}+0.5y_{12} & -y_{2222}+y_{222}+0.5y_{22}
\end{array}\right]\succeq{}0.
\]
Apart from the matrices being symmetric, notice other regular patterns between the elements. These are taken care of as additional constraints in the implementation. The optimum for the objective function is $-3/4$. The implementation reads as follows:
\begin{verbatim}
from ncpol2sdpa import generate_variables, SdpRelaxation, write_to_sdpa

# Number of Hermitian variables
n_vars = 2
# Level of relaxation
level = 2

# Get Hermitian variables
X = generate_variables(n_vars, hermitian=True)

# Define the objective function
obj = X[0] * X[1] + X[1] * X[0]

# Inequality constraints
inequalities = [-X[1] ** 2 + X[1] + 0.5]

# Equality constraints
equalities = []

# Simple monomial substitutions
monomial_substitution = {}
monomial_substitution[X[0] ** 2] = X[0]

# Obtain SDP relaxation
sdpRelaxation = SdpRelaxation(X)
sdpRelaxation.get_relaxation(obj, inequalities, equalities,
                             monomial_substitution, level)
write_to_sdpa(sdpRelaxation, 'example_noncommutative.dat-s')
\end{verbatim}

Any flavour of the SDPA family of solvers will solve the exported problem:
\begin{verbatim}
$ sdpa examplenc.dat-s examplenc.out
\end{verbatim}

If the SDPA solver is in the search path, we can invoke the solver from Python:
\begin{verbatim}
from ncpol2sdpa import solve_sdp
primal, dual = solve_sdp(sdpRelaxation)
\end{verbatim}

The relevant part of the output shows the optimum for the objective function:
\begin{verbatim}
objValPrimal = -7.5000001721851994e-01
objValDual   = -7.5000007373829902e-01
\end{verbatim}
This is close to the analytical optimum of $-3/4$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Example 2: Using PICOS and MOSEK}
A compatibility layer with PICOS allows calling a wider ranger of solvers. Assuming that the PICOS dependencies are in \verb+PYTHONPATH+ and MOSEK is also operational, we can pass an argument to the function \verb+get_relaxation+ to generate a PICOS optimization problem. Using the preliminaries of the problem outlined in Section~\ref{example1}, we change the relevant function call to:
\begin{verbatim}
P = sdpRelaxation.get_relaxation(obj, inequalities, equalities,
                           monomial_substitution, level, picos=True)
\end{verbatim}
This returns a PICOS problem, and with that, we can solve it with any solver that PICOS supports. For example, with MOSEK, we can enter:
\begin{verbatim}
P.solve(solver='mosek7')
\end{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Example 3: Bosonic system}
A more sophisticated application is  also supplied with the code (test-harmonic\_oscillator.py), which implements the Hamiltonian of a bosonic system on a 1D line. Since it uses non-Hermitian variables, a C++ implementation is currently not feasible.

The system Hamiltonian describes $N$ harmonic oscillators with a parameter $\omega$. It is the result of second quantization and it is subject to bosonic constraints on the ladder operators $a_{k}$ and $a_{k}^{\dagger}$ (see, for instance, Section~22.2 in \cite{fayngold2013quantum}). The Hamiltonian is written as
\begin{equation}
  H = \hbar \omega\sum_{i}\left(a_{i}^{\dagger}a_{i}+\frac{1}{2}\right).
\end{equation}
Here $^{\dagger}$ stands for the adjoint operation. The constraints on the ladder operators are given as
\begin{align}
[a_{i},a_{j}^{\dagger}] &=  \delta_{ij} \\
[a_{i},a_{j}]  &=  0 \nonumber \\
[a_{i}^{\dagger},a_{j}^{\dagger}] &=  0,\nonumber
\end{align}
where $[.,.]$ stands for the commutation operator $[a,b]=ab-ba$. 

Clearly, most of the constraints are monomial substitutions, except $[a_{i},a_{i}^{\dagger}]=1$, which needs to be defined as an equality. The Python code for generating the SDP relaxation is provided below. We set $\omega=1$, and we also set Planck's constant $\hbar$ to one, to obtain numerical results that are easier to interpret.
\begin{verbatim}
from sympy.physics.quantum.dagger import Dagger
from ncpol2sdpa import generate_variables,  \
                       bosonic_constraints, \
                       SdpRelaxation, write_to_sdp

# level of relaxation
level = 1

# Number of variables
N = 4

# Parameters for the Hamiltonian
hbar, omega = 1, 1

# Define ladder operators
a = generate_variables(N, name='a')

hamiltonian = 0
for i in range(N):
    hamiltonian += hbar*omega*(Dagger(a[i])*a[i]+0.5)

monomial_substitutions, equalities = bosonic_constraints(a)
inequalities = []

time0 = time.time()
#Obtain SDP relaxation
print("Obtaining SDP relaxation...")
verbose = 1
sdpRelaxation = SdpRelaxation(a)
sdpRelaxation.get_relaxation(hamiltonian, inequalities, equalities, 
                      monomial_substitutions, level, verbose)
#Export relaxation to SDPA format
print("Writing to disk...")
write_to_sdpa(sdpRelaxation, 'harmonic_oscillator.dat-s')                      
\end{verbatim}

Solving the SDP for $N=4$, for instance, gives the following result:
\begin{verbatim}
objValPrimal = +1.9999998358414430e+00
objValDual   = +1.9999993671869802e+00
\end{verbatim}
This is very close to the analytic result of 2. The result is similarly precise for arbitrary numbers of oscillators. 

It is remarkable that we get the correct value at the first level of relaxation, but this property is typical for bosonic systems~\citep{navascues2013paradox}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{thebibliography}{}

\bibitem[Fayngold and Fayngold, 2013]{fayngold2013quantum}
Fayngold, M. and Fayngold, V. (2013).
\newblock {\em Quantum Mechanics and Quantum Information}.
\newblock Wiley-VCH.

\bibitem[Joyner et~al., 2012]{joyner2012open}
Joyner, D., {\v{C}}ert{\'\i}k, O., Meurer, A., and Granger, B.~E. (2012).
\newblock Open source computer algebra systems: {SymPy}.
\newblock {\em ACM Communications in Computer Algebra}, 45(3/4):225--234.

\bibitem[Navascu\'es et~al., 2013]{navascues2013paradox}
Navascu\'es, M., Garc\'ia-S\'aez, A., Ac\'in, A., Pironio, S., and Plenio, M.~B. (2013).
\newblock A paradox in bosonic energy computations via semidefinite programming relaxations.
\newblock {\em New Journal of Physics}, 15(2): 023026.

\bibitem[Pironio et~al., 2010]{pironio2010convergent}
Pironio, S., Navascues, M., and Ac\'in, A. (2010).
\newblock Convergent relaxations of polynomial optimization problems with
  noncommuting variables.
\newblock {\em SIAM Journal on Optimization}, 20(5):2157--2180.

\bibitem[Wittek, 2014]{wittek2014ncpol2sdpa}
Wittek, P. (2014). 
\newblock Ncpol2sdpa -- Sparse Semidefinite Programming Relaxations for Polynomial Optimization Problems of Noncommuting Variables. 
\newblock {\em To appear in the ACM Transactions on Mathematical Software}.

\bibitem[Yamashita et~al., 2003]{yamashita2003sdpara}
Yamashita, M., Fujisawa, K., and Kojima, M. (2003).
\newblock {SDPARA}: Semidefinite programming algorithm parallel version.
\newblock {\em Parallel Computing}, 29(8):1053--1067.

\end{thebibliography}

\end{document}
